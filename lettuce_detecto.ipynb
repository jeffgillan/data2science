{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Lettuce Detectio with Detecto\n","\n","This notebook is a simple example of how to use the Detecto python library to detect lettuce in aerial drone images. The Detecto library is a PyTorch-based library that simplifies the process of training object detection models. \n","\n","This notebook accomplishes the following tasks:\n","1. Connects to Data to Science platform (https://ps2.d2s.org) to access the drone imagery. The dataset is an orthomosaic of a lettuce field near Yuma, Arizona.\n","2. Downloads (from Huggingface) an object detection machine learning model that has been fine-tuned to detect lettuce. The model is based on the Faster R-CNN architecture. It was trained by PhytoOracle, a research group at the University of Arizona. It was trained on Maricopa Ag Center gantry images at very high-resolution (millimeters). It is trained to use RGB images and put bounding boxes around lettuce plants.\n","3. Outputs the detected lettuce bounding boxes as a polygon shapefile layer with the same geographic coordinate system as the input drone image. "]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["#Import libraries for D2S and leafmap\n","\n","from datetime import date\n","\n","from d2spy.workspace import Workspace\n","\n","import os\n","\n","import leafmap"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["#Import necessary modules from Detecto python library\n","from detecto.core import Model #bring in the Faster R-CNN ResNet50 FPM model\n","from detecto.utils import read_image\n","from detecto.visualize import show_labeled_image"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import os\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["import geopandas as gpd\n","from shapely.geometry import box\n","import rasterio"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Connect to Purdue hosted D2S instance. It will prompt for your D2S password.\n","workspace = Workspace.connect(\"https://ps2.d2s.org\", \"jgillan@arizona.edu\")"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ID: ace74e20-ceec-45cd-b260-2a0f1c50b420\n","Title: Holiday Beach\n","Description: After Hurricane Harvey Survey\n","\n","ID: 91509636-98e7-4e2c-9a68-e9006846b52f\n","Title: Purdue PUSH\n","Description: Purdue University Student Health Service building\n","\n","ID: c15b0825-6e74-4899-b6bd-2917ce1ae3bd\n","Title: OsaLarge\n","Description: Large area including the Osa Conservation base camp.\n","\n","ID: 77a769b0-61af-4813-894a-746001759f67\n","Title: Biosphere 2\n","Description: UAS Summit On Open Science & Data Management\n","\n","ID: 2f939aa4-95e0-4b33-b0bb-e144207044ab\n","Title: Santa Rita Experimental Range\n","Description: Drone Imagery from 2019 collection\n","\n","ID: 62773825-5d03-4eb0-8439-a463c0e09b0b\n","Title: Cornell Wheat - 2023\n","Description: T3 <-> UASHUB\n","\n","ID: 2f27061b-2d66-41bd-9fd5-fc038ad34496\n","Title: Peanut Demo\n","Description: Demonstrating cloud data processing example\n","\n","ID: fbac2a0a-1c7f-4add-b276-0c2a6644711a\n","Title: Paradise Valley Country Club\n","Description: Topographic surveying of the golf course for the purpose of installing subsurface drip irrigation. \n","\n","ID: c47d1839-3d27-4d22-afc0-cdde963dd3fd\n","Title: Santa Cruz River - Pima County Flood Control\n","Description: Contract work to image a stretch of the Santa Cruz River in Tucson, Az for purposes of mapping vegetation. \n","\n","ID: 07ad970d-b09f-4de8-ad81-fcc0de82e9e6\n","Title: Swetnam House\n","Description: Drone Sfm survey of casa de Swetnam\n","\n","ID: 5cb0744a-29c4-4f51-9fc8-ddd00d6077de\n","Title: Plot C23 - Bighorn Fire Forest Monitoring \n","Description: Drone imagery survey of burned areas following the 2020 Bighorn fire in the Santa Catalina Mountains, AZ. Work sponsored by Pima County Regional Flood Control District.\n","\n","ID: 072b71a6-ac00-42dc-beae-39f3c01dd0bc\n","Title: Loma Linda - Bighorn Fire Forest Monitoring\n","Description: Drone survey of Santa Catalina Mountain post Bighorn fire in 2020. Sponsored by Pima County Regional Flood Control District. \n","\n","ID: 2b9ac2e7-44e6-497c-9a19-f8e00923d685\n","Title: Clearview Casa\n","Description: Drone survey of my house in Tucson. \n","\n","ID: d2a3778c-c4de-463a-8c4f-5dc0d601ce69\n","Title: Jemez Fuel Mapping\n","Description: Drone survey of forested neighborhood in Jemez Springs, NM\n","\n","ID: 9317d1dd-7d2e-46c3-ae2e-13380d731ca2\n","Title: Santa Rita Forage Utilization \n","Description: Drone survey of plots before and after cattle grazing\n","\n","ID: 46669dd1-3c9a-487e-adaa-92dd50bf0420\n","Title: Yuma FWOL Welton\n","Description: Welton, AZ\n","\n","ID: cfb77a4a-a065-400e-ae12-2cf11bf7c25b\n","Title: Yuma_Smithfield_50ft\n","Description: Yuma \n","\n","ID: 31edc283-bc86-4b79-a379-818072a87faa\n","Title: Yuma Syngenta Irrigation \n","Description: Lettuce\n","\n","ID: 0506fc81-6173-4d40-b14a-c48848a8612c\n","Title: Yuma Silver Acres\n","Description: Yuma Drone Imagery\n","\n","ID: cb734885-f2b5-42da-add3-530126733404\n","Title: Yuma FW Field YAC\n","Description: lettuce \n","\n"]}],"source":["# Get list of all your projects\n","projects = workspace.get_projects()\n","\n","# Check if there are any projects\n","if len(projects) > 0:\n","    # Loop through all projects and print each one\n","    for project in projects:\n","        print(f\"ID: {project.id}\")\n","        print(f\"Title: {project.title}\")\n","        print(f\"Description: {project.description}\\n\")\n","else:\n","    print(\"Please create a project before proceeding with this guide.\")\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Flight(acquisition_date='2020-10-06', name='Smithfield_50ft', altitude=20.0, side_overlap=60.0, forward_overlap=75.0, sensor='RGB', platform='Phantom_4')\n"]}],"source":["###Choose a project (from the previous print) and list all flights for that project\n","\n","# Define the project ID you're looking for\n","#project_id = \"46669dd1-3c9a-487e-adaa-92dd50bf0420\"\n","project_id = \"cfb77a4a-a065-400e-ae12-2cf11bf7c25b\"\n","\n","\n","# Find the project by ID\n","selected_project = None\n","for project in projects:\n","    if project.id == project_id:\n","        selected_project = project\n","        break\n","\n","# Check if the project was found\n","if selected_project:\n","    # Get list of all flights for the selected project\n","    flights = selected_project.get_flights()\n","\n","    # Check if there are any flights\n","    if len(flights) > 0:\n","        # Loop through all flights and print each one\n","        for flight in flights:\n","            print(flight)\n","    else:\n","        print(\"No flights found for this project.\")\n","else:\n","    print(f\"Project with ID '{project_id}' not found.\")"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["https://ps2.d2s.org/static/projects/cfb77a4a-a065-400e-ae12-2cf11bf7c25b/flights/20812f2d-4b31-45b0-9b2f-66595aac16fa/data_products/ed454526-6e85-49f8-a274-fafda388abdd/b1cdf543-0dfd-4da7-b258-edb2fad2f5bd.tif\n","https://ps2.d2s.org/static/projects/cfb77a4a-a065-400e-ae12-2cf11bf7c25b/flights/20812f2d-4b31-45b0-9b2f-66595aac16fa/data_products/08bc3a6e-5ef9-45e8-b4b8-4face6f40ce2/e16b4c86-8476-4eab-af30-2a0befab1bfc.tif\n"]}],"source":["# Get list of data products from a flight. O in this case is the first flight listed.\n","data_products = flights[0].get_data_products()\n","\n","# Check if there are any data products\n","if len(data_products) > 0:\n","    # Loop through all data products and print their URLs\n","    for product in data_products:\n","        print(product.url)\n","else:\n","    print(\"No data products found for this flight.\")\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9dd5979c1345442d8203042f511d0d36","version_major":2,"version_minor":0},"text/plain":["Map(center=[20, 0], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom_out_text…"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Interactive leafmap Map\n","os.environ[\"TITILER_ENDPOINT\"] = \"https://tt.d2s.org\"\n","\n","m = leafmap.Map()\n","\n","# URL for a D2S hosted GeoTIFF data product\n","ortho_url = \"https://ps2.d2s.org/static/projects/cfb77a4a-a065-400e-ae12-2cf11bf7c25b/flights/20812f2d-4b31-45b0-9b2f-66595aac16fa/data_products/ed454526-6e85-49f8-a274-fafda388abdd/b1cdf543-0dfd-4da7-b258-edb2fad2f5bd.tif\"\n","\n","# Add a publicly available data product to the map\n","m.add_cog_layer(ortho_url, name=\"Orthomosaic\")\n","\n","# If you want to display a private data product, comment out the previously line and uncomment the below m.add_cog_layer line\n","# Add a private data product to the map\n","# m.add_cog_layer(f\"{ortho_url}?API_KEY={api_key}\", name=\"DSM\", colormap_name=\"rainbow\")\n","\n","# Display the map\n","m"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["#Download the image from D2S to the local directory\n","#!wget https://ps2.d2s.org/static/projects/46669dd1-3c9a-487e-adaa-92dd50bf0420/flights/72e1b4a1-68ea-48bf-85d1-4f6315cd78bd/data_products/fcb09a00-181c-4e3c-ba89-e58c7e7a7223/3ac72e63-64fe-4713-af0b-c332b3851032.tif\n","\n","#!wget https://ps2.d2s.org/static/projects/cfb77a4a-a065-400e-ae12-2cf11bf7c25b/flights/20812f2d-4b31-45b0-9b2f-66595aac16fa/data_products/ed454526-6e85-49f8-a274-fafda388abdd/b1cdf543-0dfd-4da7-b258-edb2fad2f5bd.tif\n","\n","#Return the path of the downloaded image \n","image_path = \"b1cdf543-0dfd-4da7-b258-edb2fad2f5bd.tif\"\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["--2024-10-27 20:33:36--  https://huggingface.co/jgillan/phytooracle_lettuce_2/resolve/main/model_weights.pth\n","Resolving huggingface.co (huggingface.co)... 18.238.109.92, 18.238.109.52, 18.238.109.121, ...\n","Connecting to huggingface.co (huggingface.co)|18.238.109.92|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://cdn-lfs-us-1.hf.co/repos/97/92/979239b2b3de32fe9f27b49a95a9f05143f15daa6bd1473652c850bd5d752d7c/90bf60c4e8ce0b9f390f4d1887f336087a39ddb9c9199a7bff3198e44f523a00?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model_weights.pth%3B+filename%3D%22model_weights.pth%22%3B&Expires=1730345617&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMDM0NTYxN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzk3LzkyLzk3OTIzOWIyYjNkZTMyZmU5ZjI3YjQ5YTk1YTlmMDUxNDNmMTVkYWE2YmQxNDczNjUyYzg1MGJkNWQ3NTJkN2MvOTBiZjYwYzRlOGNlMGI5ZjM5MGY0ZDE4ODdmMzM2MDg3YTM5ZGRiOWM5MTk5YTdiZmYzMTk4ZTQ0ZjUyM2EwMD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=qwB8MCpByllz9t-4ISaUIiTc-L5ru0i0d35PVFf38Gy8bDriS8eCsJGInM4NEgZsxuy9ehFATU6lT2insNTeJ1JNTBaFCEsBI%7EPy8YlsAr-hxhu8I6-HNvkiU12-w4hent8pJTuRfN5L0BRahheofXfAul6bf3pbVxlIjkzSZOSGV26IwbRvnonUBJogMvZJLVHiF5sE7z360SscV6HbpmfO9lNFCwzpLmo6%7EGcRfDDHyQmfy3d9a8nsNf6fQCPs%7EmD7NXdoq8-H6pRvQ5DwImfm9BlvSG-iPRRTUSUZd2di%7EtdhttZaoQCpW-uFns2y7kxAGgzLxKudC3yF3r0uoQ__&Key-Pair-Id=K24J24Z295AEI9 [following]\n","--2024-10-27 20:33:37--  https://cdn-lfs-us-1.hf.co/repos/97/92/979239b2b3de32fe9f27b49a95a9f05143f15daa6bd1473652c850bd5d752d7c/90bf60c4e8ce0b9f390f4d1887f336087a39ddb9c9199a7bff3198e44f523a00?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model_weights.pth%3B+filename%3D%22model_weights.pth%22%3B&Expires=1730345617&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMDM0NTYxN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzk3LzkyLzk3OTIzOWIyYjNkZTMyZmU5ZjI3YjQ5YTk1YTlmMDUxNDNmMTVkYWE2YmQxNDczNjUyYzg1MGJkNWQ3NTJkN2MvOTBiZjYwYzRlOGNlMGI5ZjM5MGY0ZDE4ODdmMzM2MDg3YTM5ZGRiOWM5MTk5YTdiZmYzMTk4ZTQ0ZjUyM2EwMD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=qwB8MCpByllz9t-4ISaUIiTc-L5ru0i0d35PVFf38Gy8bDriS8eCsJGInM4NEgZsxuy9ehFATU6lT2insNTeJ1JNTBaFCEsBI%7EPy8YlsAr-hxhu8I6-HNvkiU12-w4hent8pJTuRfN5L0BRahheofXfAul6bf3pbVxlIjkzSZOSGV26IwbRvnonUBJogMvZJLVHiF5sE7z360SscV6HbpmfO9lNFCwzpLmo6%7EGcRfDDHyQmfy3d9a8nsNf6fQCPs%7EmD7NXdoq8-H6pRvQ5DwImfm9BlvSG-iPRRTUSUZd2di%7EtdhttZaoQCpW-uFns2y7kxAGgzLxKudC3yF3r0uoQ__&Key-Pair-Id=K24J24Z295AEI9\n","Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 13.224.53.61, 13.224.53.30, 13.224.53.94, ...\n","Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|13.224.53.61|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 165729397 (158M) [binary/octet-stream]\n","Saving to: ‘model_weights.pth’\n","\n","model_weights.pth   100%[===================>] 158.05M  3.78MB/s    in 40s     \n","\n","2024-10-27 20:34:17 (3.98 MB/s) - ‘model_weights.pth’ saved [165729397/165729397]\n","\n"]}],"source":["#Download the fine-tuned model (lettuce detection) from Hugging Face\n","!wget https://huggingface.co/jgillan/phytooracle_lettuce_2/resolve/main/model_weights.pth\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["#declare the labels for the fine-tuned model\n","labels = [\n","    'lettuce'\n","]"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["#Load the fine-tuned model\n","model = Model.load('model_weights.pth', labels) "]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["##Define function to crop the remotely sensed image into tiles, \n","# run predictions on each tile, and display the predictions on the original image\n","\n","# Disable the image size limit of PIL\n","Image.MAX_IMAGE_PIXELS = None\n","\n","# Step 1: Crop the large image into tiles\n","def crop_image_into_tiles(image_path, tile_size, output_folder):\n","    image = Image.open(image_path)\n","    img_width, img_height = image.size\n","    tiles_with_coordinates = []\n","\n","    if not os.path.exists(output_folder):\n","        os.makedirs(output_folder)\n","    \n","    tile_num = 0\n","    for y in range(0, img_height, tile_size):\n","        for x in range(0, img_width, tile_size):\n","            box = (x, y, min(x + tile_size, img_width), min(y + tile_size, img_height))\n","            tile = image.crop(box)\n","\n","            if tile.mode == 'RGBA':  # Convert to RGB if needed\n","                tile = tile.convert(\"RGB\")\n","\n","            tile_path = os.path.join(output_folder, f'tile_{tile_num}.jpg')\n","            tile.save(tile_path, 'JPEG')\n","            tiles_with_coordinates.append((tile_path, (x, y)))\n","            tile_num += 1\n","\n","    return tiles_with_coordinates\n","\n","# Step 2: Run predictions on each tile\n","def get_predictions_for_tiles(tiles_with_coordinates, model, threshold=0.3):\n","    all_predictions = []\n","\n","    for tile_path, (tile_x, tile_y) in tiles_with_coordinates:\n","        tile = Image.open(tile_path)\n","        \n","        # Run prediction on tile\n","        labels, boxes, scores = model.predict(tile)\n","        \n","        # Store the predictions with the tile's coordinates\n","        all_predictions.append((labels, boxes, scores, tile_x, tile_y))\n","\n","    return all_predictions\n","\n","# Step 3: Adjust and display predictions on the original image\n","def adjust_boxes(boxes, tile_x, tile_y):\n","    adjusted_boxes = []\n","    for box in boxes:\n","        x_min, y_min, x_max, y_max = box\n","        adjusted_box = [x_min + tile_x, y_min + tile_y, x_max + tile_x, y_max + tile_y]\n","        adjusted_boxes.append(adjusted_box)\n","    return adjusted_boxes\n","\n","def display_original_image_with_boxes(image_path, all_predictions, threshold=0.3):\n","    image = Image.open(image_path)\n","    fig, ax = plt.subplots(1, figsize=(100, 100))\n","    ax.imshow(image)\n","\n","    for labels, boxes, scores, tile_x, tile_y in all_predictions:\n","        adjusted_boxes = adjust_boxes(boxes, tile_x, tile_y)\n","\n","        for i, box in enumerate(adjusted_boxes):\n","            if scores[i] > threshold:\n","                x_min, y_min, x_max, y_max = box\n","                rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=3, edgecolor='r', facecolor='none')\n","                ax.add_patch(rect)\n","                #label_text = f'{labels[i]}: {scores[i]:.2f}' # Uncomment these lines to display labels and scores\n","                #plt.text(x_min, y_min - 10, label_text, color='white', fontsize=12, bbox=dict(facecolor='red', alpha=0.5))\n","\n","    plt.axis('off')\n","    plt.show()\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["\n","# Define the output folder and tile size\n","output_folder = 'cropped_tiles'\n","tile_size = 1024  # Adjust as needed\n","\n","# Run the tiling function\n","tiles_with_coordinates = crop_image_into_tiles(image_path, tile_size, output_folder)\n","\n","# Run predictions on each tile\n","all_predictions = get_predictions_for_tiles(tiles_with_coordinates, model, threshold=0.15)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Display all predictions on the original large image\n","display_original_image_with_boxes(image_path, all_predictions, threshold=0.3)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["#Define function to create a georeferenced shapefile from the predictions\n","\n","def create_georeferenced_shapefile(all_predictions, image_path, output_shapefile, threshold):\n","    # Open the original image to retrieve CRS and affine transform\n","    with rasterio.open(image_path) as src:\n","        crs = src.crs  # CRS of the original image (EPSG:32611)\n","        transform = src.transform  # Affine transformation matrix for the full image\n","\n","    # List to hold each bounding box with its label and score\n","    polygons = []\n","\n","    # Collect bounding boxes in terms of full image coordinates (not tile-based)\n","    for labels, boxes, scores, tile_x, tile_y in all_predictions:\n","        for i, box_coords in enumerate(boxes):\n","            if scores[i] >= threshold:  # Apply confidence threshold\n","                # Calculate full-image coordinates for each bounding box\n","                x_min, y_min, x_max, y_max = box_coords\n","                x_min += tile_x\n","                y_min += tile_y\n","                x_max += tile_x\n","                y_max += tile_y\n","\n","                # Create a Polygon in image (pixel) coordinates\n","                polygon = box(x_min, y_min, x_max, y_max)\n","                polygons.append({\n","                    'geometry': polygon,\n","                    'label': labels[i],\n","                    'score': scores[i]\n","                })\n","\n","    # Create a GeoDataFrame with pixel-based coordinates\n","    gdf_pixel = gpd.GeoDataFrame(polygons, crs=\"EPSG:32611\")\n","\n","    # Apply affine transform to convert pixel coordinates to geographic coordinates\n","    gdf_pixel['geometry'] = gdf_pixel['geometry'].apply(\n","        lambda geom: transform_polygon(geom, transform)\n","    )\n","\n","    # Set CRS and save to shapefile\n","    gdf_pixel.set_crs(crs, inplace=True)\n","    gdf_pixel.to_file(output_shapefile, driver=\"ESRI Shapefile\")\n","\n","def transform_polygon(geometry, transform):\n","    # Convert each coordinate in the Polygon to geographic coordinates using affine transform\n","    transformed_coords = [(transform * (x, y)) for x, y in geometry.exterior.coords]\n","    return box(*transformed_coords[0], *transformed_coords[2])\n","\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["#Execute the function to create the georeferenced shapefile\n","output_shapefile = \"predicted_please_work.shp\"\n","create_georeferenced_shapefile(all_predictions, image_path, output_shapefile, threshold=0.15)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["session ended\n"]}],"source":["# Removes access token from future requests\n","workspace.logout()"]}],"metadata":{"kernelspec":{"display_name":"lettuce_detecto","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"}},"nbformat":4,"nbformat_minor":2}
